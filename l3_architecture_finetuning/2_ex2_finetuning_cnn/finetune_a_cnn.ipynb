{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning a Convolutional Neural Network\n",
    "\n",
    "In this exercise, you will have to finetune a pretrained CNN model on the CIFAR10 dataset. The data loading and model testing logic are already included in your code. You will have to create the model and the training loop.\n",
    "\n",
    "**In this workspace you have GPU to help train the model but it is best practice to DISABLE it while writing code and only ENABLE it when you are training.** \n",
    "\n",
    "Here are the steps you need to do to complete this exercise:\n",
    "\n",
    "1. Finish the `create_model()` function. You should use a pretrained model. You are free to choose any pre-trained model that you want to use. \n",
    "2. Finish the `train()` function. This function should validate the accuracy of the model during the training stage. You should stop the training when this validation accuracy stops increasing.\n",
    "3. Save all your work and then **ENABLE** the GPU\n",
    "4. Run the file to make sure that the model is training properly.\n",
    "5. If it works, remember to **DISABLE** the GPU before moving to the next page. \n",
    "\n",
    "In case you get stuck, you can look at the solution by clicking the jupyter symbol at the top left and navigating to `finetune_a_cnn_solution.py`.\n",
    "\n",
    "## Try It Out!\n",
    "- See how your accuracy changes when using other pre-trained models.\n",
    "- Play around with the number of layers and neurons in your model. How does the accuracy change? How long does it take to train the model?\n",
    "- Can you create the same network in TensorFlow as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device cuda:0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 0, Phase train\n",
      "Images [2000/50000 (4%)] Loss: 1.32 Accuracy: 875/2000 (43.75%)\n",
      "Images [4000/50000 (8%)] Loss: 0.87 Accuracy: 2125/4000 (53.12%)\n",
      "Images [6000/50000 (12%)] Loss: 0.98 Accuracy: 3479/6000 (57.98%)\n",
      "Images [8000/50000 (16%)] Loss: 0.61 Accuracy: 4863/8000 (60.79%)\n",
      "Images [10000/50000 (20%)] Loss: 1.35 Accuracy: 6218/10000 (62.18%)\n",
      "Epoch 0, Phase valid\n",
      "Images [2000/10000 (20%)] Loss: 0.50 Accuracy: 1504/2000 (75.20%)\n",
      "Epoch 1, Phase train\n",
      "Images [2000/50000 (4%)] Loss: 0.82 Accuracy: 1405/2000 (70.25%)\n",
      "Images [4000/50000 (8%)] Loss: 0.66 Accuracy: 2832/4000 (70.80%)\n",
      "Images [6000/50000 (12%)] Loss: 0.93 Accuracy: 4235/6000 (70.58%)\n",
      "Images [8000/50000 (16%)] Loss: 1.01 Accuracy: 5667/8000 (70.84%)\n",
      "Images [10000/50000 (20%)] Loss: 1.37 Accuracy: 7082/10000 (70.82%)\n",
      "Epoch 1, Phase valid\n",
      "Images [2000/10000 (20%)] Loss: 0.76 Accuracy: 1513/2000 (75.65%)\n",
      "Testing Model on Whole Testing Dataset\n",
      "Testing Accuracy: 75.41, Testing Loss: 0.7126771843321621\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time # for measuring time for testing, remove for students\n",
    "\n",
    "def test(model, test_loader, criterion, device):\n",
    "    print(\"Testing Model on Whole Testing Dataset\")\n",
    "    model.eval()\n",
    "    running_loss=0\n",
    "    running_corrects=0\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs=inputs.to(device)\n",
    "        labels=labels.to(device)\n",
    "        outputs=model(inputs)\n",
    "        loss=criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    total_loss = running_loss / len(test_loader.dataset)\n",
    "    total_acc = running_corrects/ len(test_loader.dataset)\n",
    "    print(f\"Testing Accuracy: {100*total_acc}, Testing Loss: {total_loss}\")\n",
    "    \n",
    "def train(model, train_loader, validation_loader, criterion, optimizer, device):\n",
    "    epochs=2\n",
    "    best_loss=1e6\n",
    "    image_dataset={'train':train_loader, 'valid':validation_loader}\n",
    "    loss_counter=0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            print(f\"Epoch {epoch}, Phase {phase}\")\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_samples=0\n",
    "\n",
    "            for step, (inputs, labels) in enumerate(image_dataset[phase]):\n",
    "                inputs=inputs.to(device)\n",
    "                labels=labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase=='train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "                running_samples+=len(inputs)\n",
    "                if running_samples % 2000  == 0:\n",
    "                    accuracy = running_corrects/running_samples\n",
    "                    print(\"Images [{}/{} ({:.0f}%)] Loss: {:.2f} Accuracy: {}/{} ({:.2f}%)\".format(\n",
    "                            running_samples,\n",
    "                            len(image_dataset[phase].dataset),\n",
    "                            100.0 * (running_samples / len(image_dataset[phase].dataset)),\n",
    "                            loss.item(),\n",
    "                            running_corrects,\n",
    "                            running_samples,\n",
    "                            100.0*accuracy,\n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "                #NOTE: Comment lines below to train and test on whole dataset\n",
    "                if running_samples>(0.2*len(image_dataset[phase].dataset)):\n",
    "                    break\n",
    "\n",
    "            epoch_loss = running_loss / running_samples\n",
    "            epoch_acc = running_corrects / running_samples\n",
    "            \n",
    "            if phase=='valid':\n",
    "                if epoch_loss<best_loss:\n",
    "                    best_loss=epoch_loss\n",
    "                else:\n",
    "                    loss_counter+=1\n",
    "\n",
    "        if loss_counter==1:\n",
    "            break\n",
    "    return model\n",
    "\n",
    "def create_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False   \n",
    "\n",
    "    num_features=model.fc.in_features\n",
    "    model.fc = nn.Sequential(\n",
    "                   nn.Linear(num_features, 10))\n",
    "    return model\n",
    "\n",
    "batch_size=10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on Device {device}\")\n",
    "\n",
    "training_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "testing_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "        download=True, transform=training_transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "        download=True, transform=testing_transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "\n",
    "model=create_model()\n",
    "model=model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "train(model, trainloader, testloader, criterion, optimizer, device)\n",
    "\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remember to Disable GPU when you are done training. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
